<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184/284A Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184/284A: Computer Graphics and Imaging, Spring 2024</h1>
<h1 align="middle">Homework 1: Rasterizer</h1>
<h2 align="middle">Tia Jain and Janani Sriram</h2>

<br><br>

<div>

<h2 align="middle">Overview</h2>
<p>In this homework, we implemented a simple rasterizer capable of drawing triangles, supersampling for antialiasing, applying hierarchical transforms, and performing texture mapping with antialiasing. 
  By working through this assignment together, we learned about the intricacies of vector graphics rendering, particularly how to manage and manipulate pixels and coordinates to achieve precise outputs on the GUI. 
  The challenges of implementing Task 2 (supersampling), which could only be done with a proper understanding of the downsampling relationship between the sample buffer and frame buffer, helped further my understanding of how graphics are rendered at a low level, making this a great learning experience.</p>

<h2 align="middle">Section I: Rasterization</h2>

<h3 align="middle">Part 1: Rasterizing single-color triangles</h3>

<p>The process of "rasterization" is essentially flattening a triangle (2D geometric shape) into a 1D vector of framebuffer pixel values. 
We first assessed the 3 vertices of our triangle, and computed a "bounding box" by computing the minX, minY, maxX, and maxY. 
From there, we iterate over all the pixels within the bounding box, and for each (x,y) coordinates, we perform a point-in-triangle test from lecture. 
If the coord is inside OR on (made our check >= to account for this edge case) the triangle, we fill the framebuffer with the corresponding color.
<br><br>
Our algorithm is no worse than one that checks each sample within the bounding box of the triangle because that is essentially the time complexity of our algorithm, but we did make one main optimization.
To ensure that we always stay within image bounds, we have additional checks on minX, minY, maxX, and maxY after they are assigned in order to floor/ceil their values if they're out of bounds. 
This optimization works because if we find that a coordinate is out of bounds, we don't even need to check it since it definitely won't be in the triangle (and thus not colored), we can simply move on to the next coordinate.

<div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="docs/images/task1_writeup.png" align="middle" width="400px"/>
          <figcaption align="middle">svg/test4.png</figcaption>
        </td>
      </tr>
    </table>
  </div>

<br><br><br>

<h3 align="middle">Part 2: Antialiasing triangles</h3>

The motivation behind even making a supersampling algorithm is to mitigate the problem of aliasing (or "jaggies") that appeared in the images from Task1, which only had 1 sample per pixel.
The result ends up being an image with smoother edges (less jaggies) since with more samples, the image is higher resolution, but we downsample to the original size anyway, so it appears to be clearer. 
<br>(eg. from HW a sampling rate of 16 means 1000x1000 pixels becomes 4000x4000 samples, but we downsample back to 1000x1000 for the final result anyway.)
The way we achieve supersampling is by choosing a sampling rate (a perfect square) to indicate how many samples we want to take per pixel, sample at all those various locations, and then average out those values to determine an average color value to assign overall to the corresponding pixel.
<br><br>
The code for supersampling was similar to normal sampling, except that in addition to iterating over the pixels in the bounding box (double for loop), we also iterated over all the supersamples within each pixel (nested double for loop), calculated the exact position for the current sample, check if it's inside the triangle, and then colored the pixel accordingly.
We used an additional data structure for this called the sample_buffer, which is is it organized such that all samples for a pixel are in a contiguous block. 
For example, if the sample rate is 16, that means we sample 4x4 so 16 times per pixel and save each of these supersamples at consecutive indices in the sample_buffer. 
From there, we need to downsample this higher resolution back to the normal numer of pixels in resolve_to_framebuffer() which we did by averaging the color for all the samples for a given pixel in the sample buffer.

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="docs/images/task2_1sample.png" align="middle" width="400px"/>
        <figcaption align="middle">1 sample per pixel</figcaption>
      </td>
      <td>
        <img src="docs/images/task2_4sample.png" align="middle" width="400px"/>
        <figcaption align="middle">4 samples per pixel</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="docs/images/task2_16sample.png" align="middle" width="400px"/>
        <figcaption align="middle">16 samples per pixel</figcaption>
      </td>
    </tr>
  </table>
</div>

<br><br><br>


<h3 align="middle">Part 3: Transforms</h3>
We made our robot do a jumping jack in mid-air! His arms are outstretched upwards and his legs are outstretched towards the ground.
<br>
<div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="docs/images/my_robot.png" align="middle" width="400px"/>
          <figcaption align="middle">my_robot.svg</figcaption>
        </td>
      </tr>
    </table>
  </div>

  <br><br><br>

<h2 align="middle">Section II: Sampling</h2>

<h3 align="middle">Part 4: Barycentric coordinates</h3>
Barycentric coordinates are a coordinate system commonly used in computer graphic and geometry to express the position of a point within a triangle based on the verticies of that triangle.
Instead of the typical (x, y) coordinates, a point in barycentric coordinates is described by 3 numbers (alpha, beta, and gamma) which each represent the weight of one of the traingle's verticies in determining the point's position.
The key idea is that any point inside or on a triangle can be represented as a weighted everage of the triangle's verticies. alpha, beta, and gamma and non-negative and add up to 1.
<br>As an example, a point located exactly at the red vertex would have the red point weighted 1, indicating it's 100% infuenced by the red vertex and not at all by the other 2. On the other hand, a coordinate like x might have the green point weighted more than the other 2.
<br>Use case: Barycentric coordinates are particularly useful in graphics for shading and texture mapping (as we saw with this homework), where it is important to interpolate values across the surface of a triangle. <br>
<img src="docs/images/task4_color_triangle.png" width="50%" height="50%"></img>

<img src="docs/images/task4_writeup.png" width="50%" height="50%"></img>
<p>svg/basic/test7.svg</p>

<br><br><br>

<h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>

<p>
  Pixel sampling enables sampling using different numbers of surface points surrounding a 
  texture coordinate. In nearest pixel sampling, we choose the one surface coordinate 
  closest to the texture coordinate and use that color as the texture for the texture 
  coordinate. In bilinear pixel sampling, we linearly interpolate, or take the weighted 
  average, of the four surface coordinates surrounding the texture coordinate, using the 
  resulting linear interpolation as the texture of the texture coordinate.
</p>

<p>
  In calculating the pixel sampling, we used Barycentric coordinates (from task 4) to 
  get the relevant texture coordinate (u, v). If the alpha, beta, and gamma parameters 
  were greater than or equal to 0, the point was in the triangle; then, according to the 
  psm, we implemented either nearest-pixel or bilinear sampling. For nearest-pixel 
  sampling, we rounded the (u, v) coordinate and found the texel at (u, v). For bilinear 
  pixel sampling, we found the four nearest surface coordinates and found the linear 
  interpolations between adjacent coordinates' colors, then the linear interpolation 
  between the resulting values to get the final color for the texture coordinate.
</p>

<p>Nearest-pixel sampling vs. Bilinear sampling:</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="docs/images/nearest_1pixel.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest sampling at 1 sample per pixel</figcaption>
      </td>
      <td>
        <img src="docs/images/nearest-16pixel.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest sampling at 16 samples per pixel</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="docs/images/bilinear_1pixel.png" align="middle" width="400px"/>
        <figcaption align="middle">Bilinear sampling at 1 sample per pixel</figcaption>
      </td>
      <td>
        <img src="docs/images/bilinear-16pixel.png" align="middle" width="400px"/>
        <figcaption align="middle">Bilinear sampling at 16 samples per pixel</figcaption>
      </td>
    </tr>
  </table>
</div>

<p>
  Nearest sampling tends to have more jaggies in contrast to bilinear sampling, which produces a smoother blur.<br>
  1 pixel supersampling has sharper distinctions between elements of an image since the color distinctions are sharper, 
  while 16 pixel supersampling tends to have more gradual changes between colors.
</p>

<br><br><br>

<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>
<p>
  Level sampling enables sampling at different mipmap levels, where mipmaps are different resolutions of the same image. Mipmaps are particularly useful
  when trying to store a number of resolutions within a finite amount of space; for an image that takes up space N, a mipmap with D levels takes only 
  4N/3 space.
  <br><br>
  We used level sampling for texture mapping by considering the three 
  variations of level sampling. For L_ZERO, we set the mipmap level to 0, 
  implying that we wanted to use the first, largest mipmap. For L_NEAREST, 
  we found the closest mipmap level by implementing the helper function 
  get_level(), which finds the difference vectors to eventually 
  calculate the mipmap level. For L_LINEAR, we calculated the floored 
  and ceil-ed mipmap levels and the pixel sampling for each of those 
  mipmaps, then linearly interpolated the pixel samples with each 
  other for the resulting image.
</p>

<p>
  When considering L_ZERO, L_NEAREST, and L_LINEAR interpolation for level sampling, L_ZERO is the fastest, then L_NEAREST, 
  then L_LINEAR. L_LINEAR takes the most space, since it needs to compute the nearest or bilinear 
  samples for two mipmaps, then take the average.
  <br><br>
  L_LINEAR actually makes the image look a little grainy when using the psm setting 
  P_NEAREST, but blurs well when used with P_LINEAR; it seems that trilinear sampling 
  produces the best blur but takes the most memory. As a result, trilinear sampling 
  seems to work the best for antialiasing. Nearest level, bilinear interpolation also 
  produced a very smooth blur, perhaps even better than trilinear interpolation.
</p>

<p>Different combinations of pixel and level sampling for <i>sloth.png</i> :</p>

<p>
  L_ZERO, P_NEAREST: jaggies, visible and unclear boundaries<br>
  L_ZERO, P_LINEAR: smoother edges (no jaggies), but sharp distinction between colors (not blurred)<br>
  L_NEAREST, P_NEAREST: like L_ZERO, P_NEAREST but with sharper distinctions between colors within shapes<br>
  L_NEAREST, P_LINEAR: very smooth blurring (resulting in a slightly fuzzy image), smooth edges (no jaggies)
</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="docs/images/lzero_pnearest.png" align="middle" width="400px"/>
        <figcaption align="middle">L_ZERO, P_NEAREST</figcaption>
      </td>
      <td>
        <img src="docs/images/lzero_pnearest_zoom.png" align="middle" width="400px"/>
        <figcaption align="middle"></figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="docs/images/lzero_plinear.png" align="middle" width="400px"/>
        <figcaption align="middle">L_ZERO, P_LINEAR</figcaption>
      </td>
      <td>
        <img src="docs/images/lzero_plinear_zoom.png" align="middle" width="400px"/>
        <figcaption align="middle"></figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="docs/images/lnearest_pnearest.png" align="middle" width="400px"/>
        <figcaption align="middle">L_NEAREST, P_NEAREST</figcaption>
      </td>
      <td>
        <img src="docs/images/lnearest_pnearest_zoom.png" align="middle" width="400px"/>
        <figcaption align="middle"></figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="docs/images/lnearest_plinear.png" align="middle" width="400px"/>
        <figcaption align="middle">L_NEAREST, P_LINEAR</figcaption>
      </td>
      <td>
        <img src="docs/images/lnearest_plinear_zoom.png" align="middle" width="400px"/>
        <figcaption align="middle"></figcaption>
      </td>
    </tr>
  </table>
</div>


<h2 align="middle">Section III: Art Competition</h2>
<p>If you are not participating in the optional art competition, don't worry about this section!</p>

<h3 align="middle">Part 7: Draw something interesting!</h3>

</body>
</html>
